{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot.metrics as splt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_full_training_set = 'KDDTrain+.csv' \n",
    "file_path_test = 'KDDTest+.csv'  \n",
    "\n",
    "df = pd.read_csv(file_path_full_training_set)\n",
    "test_df = pd.read_csv(file_path_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack', 'level']\n",
    "df.columns = cols\n",
    "test_df.columns = cols\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(pd.isnull(df.T), cbar=False)\n",
    "\n",
    "pd.concat([df.isnull().sum(), 100 * df.isnull().sum()/len(df)], \n",
    "              axis=1).rename(columns={0:'Missing Records', 1:'Percentage (%)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, cols, title):\n",
    "    grid = gridspec.GridSpec(10, 2, wspace=0.5, hspace=0.5) \n",
    "    fig = plt.figure(figsize=(15,25)) \n",
    "    \n",
    "    for n, col in enumerate(df[cols]):         \n",
    "        ax = plt.subplot(grid[n]) \n",
    "\n",
    "        ax.hist(df[col], bins=20) \n",
    "        #ax.set_ylabel('Count', fontsize=12)\n",
    "        ax.set_title(f'{col} distribution', fontsize=15) \n",
    "    \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    grid.tight_layout(fig, rect=[0, 0, 1, 0.97])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_cols = [ 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
    "\n",
    "plot_hist(df, rate_cols, 'Ratio Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_cols = [ 'duration', 'src_bytes', 'dst_bytes', 'hot', 'num_compromised', 'num_root', 'count', 'srv_count', 'dst_host_count', 'dst_host_srv_count']\n",
    "    \n",
    "plot_hist(df, hist_cols, 'Integer Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attack_state'] = df['attack'].map(lambda x: 0 if x == 'normal' else 1)\n",
    "test_df['attack_state'] = test_df['attack'].map(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.attack_state == 1).sum()/len(df) #No.of attack states in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.attack_state == 1).sum()/len(df) # No.of attack states in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x=\"attack_state\", fill=True, common_norm=False, palette=\"crest\", alpha=.2, linewidth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_count = (df.attack_state == 1).sum()\n",
    "non_attack_count = (df.attack_state == 0).sum()\n",
    "myData = [attack_count, non_attack_count]\n",
    "\n",
    "my_labels = 'Attack Count', 'Non-Attack Count'\n",
    "plt.pie(myData, labels=my_labels, autopct='%1.1f%%')\n",
    "plt.title('Attack Ratio')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoS_attacks = ['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm','worm']\n",
    "Probe_attacks = ['ipsweep','mscan','nmap','portsweep','saint','satan']\n",
    "U2R = ['buffer_overflow','loadmdoule','perl','ps','rootkit','sqlattack','xterm']\n",
    "R2L = ['ftp_write','guess_passwd','http_tunnel','imap','multihop','named','phf','sendmail','snmpgetattack','snmpguess','spy','warezclient','warezmaster','xclock','xsnoop']\n",
    "\n",
    "attack_labels = ['Normal','DoS','Probe','U2R','R2L']\n",
    "\n",
    "def class_attack(attack):\n",
    "    if attack in DoS_attacks:\n",
    "        attack_type = 1\n",
    "    elif attack in Probe_attacks:\n",
    "        attack_type = 2\n",
    "    elif attack in U2R:\n",
    "        attack_type = 3\n",
    "    elif attack in R2L:\n",
    "        attack_type = 4\n",
    "    else:\n",
    "        attack_type = 0       \n",
    "    return attack_type\n",
    "\n",
    "#Create the attack_class column and add it to the dataset with the numerical equivalent of each class of attack.\n",
    "attack_class = df.attack.apply(class_attack)\n",
    "df['attack_class'] = attack_class\n",
    "\n",
    "test_attack_class = test_df.attack.apply(class_attack)\n",
    "test_df['attack_class'] = test_attack_class\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal = (df.attack_class == 0).sum()/len(df)\n",
    "print('Normal = {:.2f}%'.format(Normal * 100))\n",
    "DoSDDoS = (df.attack_class == 1).sum()/len(df)\n",
    "print('DoS/DDoS = {:.2f}%'.format(DoSDDoS * 100))\n",
    "Probe = (df.attack_class == 2).sum()/len(df)\n",
    "print(\"Probe = {:.2f}%\".format(Probe * 100))\n",
    "U2R = (df.attack_class == 3).sum()/len(df)\n",
    "print('U2R = {:.2f}%'.format(U2R * 100))\n",
    "R2L = (df.attack_class == 4).sum()/len(df)\n",
    "print('R2L = {:.2f}%'.format(R2L * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal = (test_df.attack_class == 0).sum()/len(test_df)\n",
    "print('Normal = {:.2f}%'.format(Normal * 100))\n",
    "DoSDDoS = (test_df.attack_class == 1).sum()/len(test_df)\n",
    "print('DoS/DDoS = {:.2f}%'.format(DoSDDoS * 100))\n",
    "Probe = (test_df.attack_class == 2).sum()/len(test_df)\n",
    "print(\"Probe = {:.2f}%\".format(Probe * 100))\n",
    "U2R = (test_df.attack_class == 3).sum()/len(test_df)\n",
    "print('U2R = {:.2f}%'.format(U2R * 100))\n",
    "R2L = (test_df.attack_class == 4).sum()/len(test_df)\n",
    "print('R2L = {:.2f}%'.format(R2L * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_vs_class = pd.crosstab(index=df.attack_class, columns=df.attack)\n",
    "attack_vs_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_vs_DDoS = pd.crosstab(df.attack_class, df.attack == \"DoS/DDoS\")\n",
    "attack_vs_DDoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bake_pies(data_list,labels):\n",
    "    list_length = len(data_list)\n",
    "    \n",
    "    # setup for mapping colors\n",
    "    color_list = sns.color_palette()\n",
    "    color_cycle = itertools.cycle(color_list)\n",
    "    cdict = {}\n",
    "    \n",
    "    # build the subplots\n",
    "    fig, axs = plt.subplots(1, list_length,figsize=(18,10), tight_layout=False)\n",
    "    plt.subplots_adjust(wspace=1/list_length)\n",
    "    \n",
    "    # loop through the data sets and build the charts\n",
    "    for count, data_set in enumerate(data_list): \n",
    "        \n",
    "        # update our color mapt with new values\n",
    "        for num, value in enumerate(np.unique(data_set.index)):\n",
    "            if value not in cdict:\n",
    "                cdict[value] = next(color_cycle)\n",
    "       \n",
    "        # build the wedges\n",
    "        wedges,texts = axs[count].pie(data_set,\n",
    "                           colors=[cdict[v] for v in data_set.index])\n",
    "\n",
    "        # build the legend\n",
    "        axs[count].legend(wedges, data_set.index,\n",
    "                           title=\"Durum\",\n",
    "                           loc=\"center left\",\n",
    "                           bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "        # set the title\n",
    "        axs[count].set_title(labels[count])\n",
    "        \n",
    "    return axs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoS_DDoS_class = df.loc[df.attack_class == 1].attack.value_counts()\n",
    "probe_class = df.loc[df.attack_class == 2].attack.value_counts()\n",
    "\n",
    "flag_axs = bake_pies([DoS_DDoS_class, probe_class], ['DoS/DDoS','Probe'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U2R_class = df.loc[df.attack_class == 3].attack.value_counts()\n",
    "R2L_class = df.loc[df.attack_class == 4].attack.value_counts()\n",
    "\n",
    "flag_axs = bake_pies([U2R_class,R2L_class], ['U2R','R2L'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = (df.attack_class == 0).sum()\n",
    "dos_ddos = (df.attack_class == 1).sum()\n",
    "probe = (df.attack_class == 2).sum()\n",
    "u2r = (df.attack_class == 3).sum()\n",
    "r2l = (df.attack_class == 4).sum()\n",
    "attack_classes = [normal, dos_ddos, probe, u2r, r2l]\n",
    "\n",
    "labels = ['Normal', 'DoS/DDoS', 'Probe', 'U2R', 'R2L']\n",
    "plt.pie(attack_classes, labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Attack Classes\\n\\n')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_vs_protocol = pd.crosstab((df.attack_class == 1), df.protocol_type)\n",
    "attack_vs_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icmp = attack_vs_protocol.icmp.sum()\n",
    "tcp = attack_vs_protocol.tcp.sum()\n",
    "udp = attack_vs_protocol.udp.sum()\n",
    "myData = [icmp , tcp,udp]\n",
    "my_labels = 'icmp','tcp' ,'udp' \n",
    "plt.pie(myData,labels=my_labels ,autopct='%1.1f%%')\n",
    "plt.title('protocol type\\n\\n')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_df = df.groupby(['attack', 'protocol_type']).size().reset_index(name='counts')\n",
    "protocol_pivot = protocol_df.pivot(index='attack', columns='protocol_type', values='counts')\n",
    "protocol_pivot = protocol_pivot.fillna(0)\n",
    "\n",
    "bake_pies([protocol_pivot.icmp, protocol_pivot.tcp, protocol_pivot.udp], ['icmp', 'tcp', 'udp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_services = df.loc[df.attack_class == 0].service.value_counts()\n",
    "DDoS_attack_services = df.loc[df.attack_class == 1].service.value_counts()\n",
    "\n",
    "flag_axs = bake_pies([normal_services, DDoS_attack_services], ['normal','DDoS_attack'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_vs_protocol = pd.crosstab(df.service, df.protocol_type,)\n",
    "service_vs_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bake_pies([service_vs_protocol.icmp, service_vs_protocol.tcp, service_vs_protocol.udp], ['icmp', 'tcp', 'udp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['protocol_type','service','flag'],prefix=\"\",prefix_sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(test_df,columns=['protocol_type','service','flag'],prefix=\"\",prefix_sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['attack' ]  \n",
    "df.drop(drop_cols, axis=1, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['attack' ]  \n",
    "test_df.drop(drop_cols, axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[df.attack_class == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test= test_df[test_df.attack_class == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDoS = df[df.attack_class == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDoS_test= test_df[test_df.attack_class == 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.concat([normal, DDoS], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_test = pd.concat([normal_test, DDoS_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= total_data.corr()\n",
    "corr_y = abs(corr['attack_class'])\n",
    "highest_corr = corr_y[corr_y > 0.1]\n",
    "highest_corr.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= total_data_test.corr()\n",
    "corr_y = abs(corr['attack_class'])\n",
    "highest_corr_test = corr_y[corr_y >0.1]\n",
    "highest_corr_test.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_corr_columns= highest_corr.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_corr_test_columns= highest_corr_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "g=sns.heatmap(total_data[highest_corr.index].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "g=sns.heatmap(total_data_test[highest_corr_test.index].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = df.loc[:,[i for i in list(df.columns) if i not in [\n",
    "'diff_srv_rate',                \n",
    "'dst_host_same_src_port_rate', \n",
    "'REJ',\n",
    "'tcp',                            \n",
    "'ecr_i',                         \n",
    "'rerror_rate',                    \n",
    "'srv_rerror_rate',                \n",
    "'dst_host_srv_rerror_rate',       \n",
    "'dst_host_rerror_rate',           \n",
    "'smtp',                           \n",
    "'dst_host_srv_diff_host_rate',    \n",
    "'domain_u',                       \n",
    "'udp',                            \n",
    "'srv_diff_host_rate',             \n",
    "'private',                        \n",
    "'dst_host_count',                 \n",
    "'http',                           \n",
    "'logged_in',                      \n",
    "'count',\n",
    "'dst_host_srv_count',             \n",
    "'dst_host_same_srv_rate',         \n",
    "'serror_rate',                    \n",
    "'srv_serror_rate',                \n",
    "'dst_host_serror_rate',           \n",
    "'S0',                             \n",
    "'dst_host_srv_serror_rate',       \n",
    "'SF',                             \n",
    "'same_srv_rate',                 \n",
    "'attack_state',                  \n",
    "'attack_class', \n",
    "'other',\n",
    "'icmp',                         \n",
    "'wrong_fragment',               \n",
    "'dst_host_diff_srv_rate',   \n",
    "'RSTO',\n",
    "'ftp_data',\n",
    "'Z39_50',\n",
    "'uucp'                          \n",
    "]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_cols = ['wrong_fragment','duration','src_bytes','dst_bytes','land','urgent','hot','num_failed_logins','num_compromised','root_shell','su_attempted','num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','srv_count']  \n",
    "df.drop(drop_cols, axis=1, inplace=True)  \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols1 = test_df.loc[:,[i for i in list(test_df.columns) if i not in [\n",
    "'diff_srv_rate',                \n",
    "'dst_host_same_src_port_rate', \n",
    "'REJ',\n",
    "'tcp',                            \n",
    "'ecr_i',                         \n",
    "'rerror_rate',                    \n",
    "'srv_rerror_rate',                \n",
    "'dst_host_srv_rerror_rate',       \n",
    "'dst_host_rerror_rate',           \n",
    "'smtp',                           \n",
    "'dst_host_srv_diff_host_rate',    \n",
    "'domain_u',                       \n",
    "'udp',                            \n",
    "'srv_diff_host_rate',             \n",
    "'private',                        \n",
    "'dst_host_count',                 \n",
    "'http',                           \n",
    "'logged_in',                      \n",
    "'count',                          \n",
    "'dst_host_srv_count',             \n",
    "'dst_host_same_srv_rate',         \n",
    "'serror_rate',                    \n",
    "'srv_serror_rate',                \n",
    "'dst_host_serror_rate',           \n",
    "'S0',                             \n",
    "'dst_host_srv_serror_rate',       \n",
    "'SF',                             \n",
    "'same_srv_rate',                 \n",
    "'attack_state',                 \n",
    "'attack_class', \n",
    "'other',\n",
    "'icmp',                         \n",
    "'wrong_fragment',               \n",
    "'dst_host_diff_srv_rate',   \n",
    "'RSTO',\n",
    "'ftp_data',\n",
    "'Z39_50',\n",
    "'uucp'\n",
    "]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop_cols = ['src_bytes','dst_bytes','land','wrong_fragment','urgent','hot','num_failed_logins','num_compromised','root_shell','su_attempted','num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','srv_count' ,'dst_host_same_src_port_rate']  \n",
    "test_df.drop(drop_cols1, axis=1, inplace=True)  \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CLASSIFICATION WITHOUT NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop('attack_class'  , axis = 1)\n",
    "X_test = test_df.drop('attack_class' , axis = 1)\n",
    "y_train = df['attack_class']\n",
    "y_test = test_df['attack_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(data_set,predictions,y):\n",
    "    prediction_series = pd.Series(predictions, index=y.index)\n",
    "\n",
    "    # we need to add the predicted and actual outcomes to the data\n",
    "    predicted_vs_actual = data_set.assign(predicted=prediction_series)\n",
    "    original_data = predicted_vs_actual.assign(actual=y).dropna()\n",
    "    conf_matrix = confusion_matrix(original_data['actual'], \n",
    "                                   original_data['predicted'])\n",
    "    \n",
    "    # capture rows with failed predictions\n",
    "    base_errors = original_data[original_data['actual'] != original_data['predicted']]\n",
    "    \n",
    "    # drop columns with no value\n",
    "    non_zeros = base_errors.loc[:,(base_errors != 0).any(axis=0)]\n",
    "\n",
    "    # idetify the type of error\n",
    "    false_positives = non_zeros.loc[non_zeros.actual==0]\n",
    "    false_negatives = non_zeros.loc[non_zeros.actual==1]\n",
    "\n",
    "    # put everything into an object\n",
    "    prediction_data = {'data': original_data,\n",
    "                       'confusion_matrix': conf_matrix,\n",
    "                       'errors': base_errors,\n",
    "                       'non_zeros': non_zeros,\n",
    "                       'false_positives': false_positives,\n",
    "                       'false_negatives': false_negatives}\n",
    "    \n",
    "    return prediction_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, gnb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gnb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "dt_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn = knn.fit(X_train , y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, knn_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = RandomForestClassifier()\n",
    "rm.fit(X_train,y_train)\n",
    "rm_pred=rm.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, rm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, rm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rm_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svm_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION WITH NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train = mms.fit_transform(X_train) \n",
    "X_test= mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, gnb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gnb_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "dt_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, dt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn = knn.fit(X_train , y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = RandomForestClassifier()\n",
    "rm.fit(X_train,y_train)\n",
    "rm_pred=rm.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, rm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, rm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rm_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.plot_confusion_matrix(y_test, svm_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
